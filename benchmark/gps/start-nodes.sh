#!/bin/bash -e

# A modified version of master-scripts/start_gps_nodes.sh made friendlier
# for automation. This incorporates scripts/start_gps_node.sh, so worker
# machines no longer need to be updated with that script. HDFS output paths,
# log paths, etc. remain unchanged.
#
# Each machine can have *multiple* workers. Hence, we refer to physical
# machines as "machines" and workers as "workers" or "slaves".
#
# Workers are started asynchronously, which is faster. This script (i.e.,
# the master) waits until all workers are done computations before exiting,
# making it either to script benchmarks. (Although a sleep delay is still
# required---see the batch benching scripts.)
#
# Because of how GPS behaves, the # of workers argument is actually IGNORED.
# Instead, we use # of workers specificied in machine config file.
# Specifically:
#
#  >> If argument < # of actual workers, we start # of actual workers.
#     (Otherwise, GPS will hang waiting for the extra workers)
#  >> If argument > # of actual workers, we start # of actual workers.
#     (Because no ports are specified for extra non-existent workers)
#

#
# To change max JVM heap size for GPS workers, see ../common/get-configs.sh.
#

# To use this, pass in arguments like:
#
#./start-nodes.sh ${workers} quick-start \
#    -ifs /user/${USER}/input/${inputgraph} \
#    -hcf "$HADOOP_DIR"/conf/core-site.xml \
#    -jc gps.examples.pagerank.PageRankVertex###JobConfiguration \
#    -mcfg /user/${USER}/gps-machine-config/cs848.cfg \
#    -log4jconfig "$GPS_DIR"/conf/log4j.config \
#    -other -max###30
#
# Note that GPS's default start script requires 3rd argument
# and onwards to be double-quoted, i.e.:
#
#./master-scripts/start_gps_nodes.sh ${workers} quick-start \
#    "-ifs /user/${USER}/input/${inputgraph} \
#     -hcf \"$HADOOP_DIR\"/conf/core-site.xml \
#     -jc gps.examples.pagerank.PageRankVertex###JobConfiguration \
#     -mcfg /user/${USER}/gps-machine-config/cs848.cfg \
#     -log4jconfig \"$GPS_DIR\"/conf/log4j.config \
#     -other -max###30"
#
#
# To start multiple workers per machine, modify the machine config file
# to be, e.g.
#
# cloud1
# cloud1
# cloud2
# cloud2
#
#
# Side note: one way to get automation when using the original gps_start_nodes.sh
# is by modifying the last slave's start_gps_node.sh to not have the "&". That way,
# since slaves are started sequentially, the last one will return only when the
# computation is complete.

if [ $# -lt 3 ]; then
    echo "usage: $0 workers mode gps-args"
    echo ""
    echo "mode: use 'quick-start' (without quotes)"
    echo "gps-args: arguments passed to GPS jar, unquoted"
    exit -1
fi

commondir=$(dirname "${BASH_SOURCE[0]}")/../common
source "$commondir"/get-hosts.sh
source "$commondir"/get-dirs.sh
source "$commondir"/get-configs.sh


OUTPUT_DIR=/user/${USER}/gps/output/

## start master
MASTER_GPS_ID=-1
GPS_MASTER_XMS=50M     # initial heap size (master)

echo "Using args: ${gps-args}"

echo "Starting GPS master -1"
"$JAVA_DIR"/bin/java -Xincgc -Xms${GPS_MASTER_XMS} -Xmx${GPS_MASTER_XMX} -verbose:gc -jar "$GPS_DIR"/gps_node_runner.jar -machineid ${MASTER_GPS_ID} -ofp "$OUTPUT_DIR"/${2}-machine-stats ${@:3} &> "$GPS_LOG_DIR"/${2}-machine${i}-output.txt &

## start slaves asynchronously (faster this way)
GPS_WORKER_XMS=256M   # initial heap size (workers)

# We don't use a slaves file as it's redundant: it would have to be
# generated by init exactly as follows, only to be re-parsed here.
w_id=0
for ((i = 1; i <= ${machines}; i++)); do
    for ((j = 1; j <= ${GPS_WPM}; j++)); do
        echo "Starting GPS worker ${w_id}"

        ssh ${name}${i} "\"$JAVA_DIR\"/bin/java -Xincgc -Xms${GPS_WORKER_XMS} -Xmx${GPS_WORKER_XMX} -verbose:gc -jar \"$GPS_DIR\"/gps_node_runner.jar -machineid ${w_id} -ofp \"$OUTPUT_DIR\"/${2}-output-${w_id}-of-$((${1}-1)) ${@:3} &> \"$GPS_LOG_DIR\"/${2}-machine${w_id}-output.txt" &

        w_id=$((w_id+1))
    done
done

# ...and wait until computation completes
wait
echo "Computation complete!"